---
title: "1. Limpiando la data"
author: "Santiago Sotelo"
date: 10/05/2022
execute: 
  echo: false
---

```{r}
#| include: false
pacman::p_load(tidyverse, rio, gt, here, janitor, fs)
here::i_am("1. limpiando_data.qmd")

```

## Problema

-   Se necesita procesar los diferentes excels en los que se encuentran los hashtags en cuestión. La totalidad de la data tiene las siguientes características:
    -   **`r fs::dir_info("archivos/4. Bases de datos con Análisis") %>% nrow()`** archivos.
    -   La totalidad de los archivos excels pesa alrededor de **`r fs::dir_info("archivos/4. Bases de datos con Análisis") %>% summarise(size=sum(size))`B**.

## Objetivo

-   Juntar toda la data útil en un solo archivo.
    -   Hojas de cálculo a utilizar: *Edges*, *Vertices*.

## Importar data

```{r}
base_central<-import("archivos/2. Procesamiento de la información/Base Central.xlsx") %>% 
  clean_names() %>% 
  mutate(
    source = paste(fecha, " #", hashtag, ".xlsx", sep = ""),
    source = str_to_lower(source),
    .before = everything()
  )

hashtags_dic<-haven::read_sav("archivos/2. Procesamiento de la información/Base_RedesyPandemia.sav") %>% 
  labelled::look_for()

hashtags<-
  base_central %>% 
  rename(periodo=6) %>% 
  mutate(
    tipo = case_when(
      tipo == 1 ~ "Lúdico",
      tipo == 2 ~ "Apoyo Social",
      tipo == 3 ~ "Crisis Sanitaria",
      tipo == 4 ~ "Político"
    ),
    periodo = case_when(
      periodo == 1 ~ "Cuarentena (marzo y abril)",
      periodo == 2 ~ "Reanudación (mayo)"
    ),
    cuartiles_de_sentimiento_polaridad = case_when(
      cuartiles_de_sentimiento_polaridad == 1 ~ "Muy Negativo",
      cuartiles_de_sentimiento_polaridad == 2 ~ "Negativo",
      cuartiles_de_sentimiento_polaridad == 3 ~ "Poco Negativo",
      cuartiles_de_sentimiento_polaridad == 4 ~ "Neutro",
      cuartiles_de_sentimiento_polaridad == 5 ~ "Poco Positivo",
      cuartiles_de_sentimiento_polaridad == 6 ~ "Positivo",
      cuartiles_de_sentimiento_polaridad == 7 ~ "Muy Positivo"
    ),
    
    across(
      c(average_geodesic_distance,
      graph_density,
      average_betweenness_centrality,
      average_closeness_centrality,
      average_eigenvector_centrality),
      ~as.numeric(str_replace(., ",", ".")) #cambiar las comas por puntos y luego a numérica
    )
    
  )

xlsx_files <- fs::dir_ls("archivos/4. Bases de datos con Análisis", regexp = "\\.xlsx$")[fs::dir_ls("archivos/4. Bases de datos con Análisis", regexp = "\\.xlsx$") %>% str_which("Copy", negate = TRUE)]

edges<- 
  xlsx_files %>% #lista de vectores
  map(import, skip = 1) %>%   #eliminar columnas extras presentes en algunas bases.
  map(
    ~ .x %>%
      clean_names() %>% 
      drop_na(vertex_1) %>% #remover filas que tienen la columna vertex_1 vacía. Se removieron un total de 727 filas. #dia52 tenía 725 filas vacías
      {if("vertex_1_group" %in% names(.)) select(.,-vertex_1_group) else .} %>% # en #Coronavid19-OFi.xlsx, #Coronavid19-OFi-Copy.xlsx, #YoApoyoAlCapitanCueva.xlsx
      {if("vertex_2_group" %in% names(.)) select(.,-vertex_2_group) else .} %>% # en #Coronavid19-OFi.xlsx, #Coronavid19-OFi-Copy.xlsx, #YoApoyoAlCapitanCueva.xlsx
      {if("edge_weight" %in% names(.)) select(.,-edge_weight) else .} %>% # en #Coronavid19-OFi.xlsx, #Coronavid19-OFi-Copy.xlsx, 
      {if("vertex_3" %in% names(.)) select(.,-vertex_3) else .} %>% # en #D+≠a65.xlsx
      {if("vertex_22" %in% names(.)) select(.,-vertex_22) else .} # en #D+≠a65.xlsx
  ) %>% 
  map_dfr(as.data.frame, .id = "source") %>% #unir todas las bases en un solo archivo
  separate(source, into = c(NA, NA, "source"), sep = "/") %>%   #primera columna nombre del excel.
  mutate(
    source = substring(source, 16),
    source = str_to_lower(source),
    source = str_replace(source, "_", " "),
    source = str_replace(source, "  ", " "),
    source = str_replace(source, "##", "#"),
    source = str_replace(source, "_", " "),
    source = str_replace(source, '"', ''),
    
    # discrepancias entre base_central y edges
    source = case_when(
      source %in% "2020-03-29 #enestacuarentenasupeque.xlsx" ~ "2020-03-29 #enestacuarentenasupe.xlsx",
      source %in% "2020-04-10 #lodescubresenlacuarentena.xlsx" ~ "2020-04-10 #lodescubresencuarentena.xlsx",
      source %in% "2020-04-13 #explotacionperfecta.xlsx" ~ "2020-04-13 #explotacionperfecto.xlsx",
      source %in% "2020-04-14 #“carretera central”.xlsx" ~ "2020-04-14 #carreteracentral.xlsx",
      source %in% "2020-04-19 #trabandoconfuerza.xlsx" ~ "2020-04-19 #trabajandoconfuerza.xlsx",
      source %in% "2020-04-23 #lacuarentenaseextiendehasta.xlsx" ~ "2020-04-23 #lacuatentenaseextiendehasta.xlsx",
      source %in% "2020-04-24 #bonofamiliaruniversal.xlsx" ~ "2020-04-24 #bonouniversalfamiliar.xlsx",
      source %in% "2020-04-28 #en40tenaaprend+≠.xlsx" ~ "2020-04-28 #en40tenaaprendí.xlsx",
      source %in% "2020-04-30 #digonomas.xlsx" ~ "2020-04-30 #digonomás.xlsx",
      source %in% "2020-05-03 #conlacuarentenaaprend+≠.xlsx" ~ "2020-05-03 #conlacuarentenaaprendí.xlsx",
      source %in% "2020-05-03 #dia49.xlsx" ~ "2020-05-03 #día49.xlsx",
      source %in% "2020-05-04 #corrupci+›nsinmascarilla.xlsx" ~ "2020-05-04 #corrupciónsinmascarilla.xlsx",
      source %in% "2020-05-05 #dia51.xlsx" ~ "2020-05-05 #día51.xlsx",
      source %in% "2020-05-06 #dia52.xlsx" ~ "2020-05-06 #día52.xlsx",
      source %in% "2020-05-19 #d+≠a65.xlsx" ~ "2020-05-19 #dia65.xlsx",
      source %in% "2020-05-19 #extra+›otodomenos.xlsx" ~ "2020-05-19 #extrañotodomenos.xlsx",
      source %in% "2020-05-22 #unmesm+°ssin.xlsx" ~ "2020-05-22 #unmesmássin.xlsx",
      
      TRUE ~ source
    )
    ) %>% 
  janitor::remove_empty("cols") %>%  #remover columnas vacías. de 41 variables a 26 variables
  left_join(hashtags %>% select(source, tipo), by = "source") %>% 

  mutate(
    # por alguna razón tecuidoperu no esta en base central
    tipo = case_when(
      source %in% "2020-05-14 #tecuidoperu.xlsx" ~ "Apoyo Social",
      TRUE ~ tipo
    )
  )
  
vertices<-
  xlsx_files %>% 
  map(import, skip = 1, sheet = 2) %>% 
  map(
    ~ .x %>%
      clean_names() %>%
      drop_na(vertex) %>% #remover filas que tienen la columna vertex_1 vacía. Se removieron un total de 1447 filas. #dia62 tenía todas las filas vacías
      {if("vertex_group" %in% names(.)) select(.,-vertex_group) else .} %>% 
      {if("columna1" %in% names(.)) select(.,-columna1) else .} %>% # en #DigoNomas
      {if("columna2" %in% names(.)) select(.,-columna2) else .} # en #DigoNomas
  ) %>% 
  map_dfr(as.data.frame, .id = "source") %>%  #unir todas las bases en un solo archivo
  separate(source, into = c(NA, NA, "source"), sep = "/") %>% #primera columna nombre del excel.
  janitor::remove_empty("cols") #remover columnas vacías. de 52 variables a 35 variables

```

-   Hay archivos con el sufijo `-Copy` en el nombre lo cual denota que es un duplicado de un hashtag. He omitido este excel.
-   El archivo `...Coronavid19-OFI` tiene el sufijo `-OFI` lo cual no es parte del hashtag. Se ha estandarizado.
-   **Edges**
    -   Las bases de datos unificadas de edges tienen **`r edges %>% nrow()`** observaciones y **`r edges %>% ncol()`** variables.
    -   El objeto creado en R que unifica todas las bases de datos de edges ocupa **`r scales::unit_format(unit = "MB", scale = 1e-6, accuracy = 0.01)(as.numeric(lobstr::obj_size(edges)))`** de la memoria RAM en la computadora.
-   **Vértices**
    -   Las bases de datos unificadas de vértices tienen **`r vertices %>% nrow()`** observaciones y **`r vertices %>% ncol()`** variables.
    -   El objeto creado en R que unifica todas las bases de datos de vértices ocupa **`r scales::unit_format(unit = "MB", scale = 1e-6, accuracy = 0.01)(as.numeric(lobstr::obj_size(vertices)))`** de la memoria RAM en la computadora.
-   **Hashtags**
    -   Las bases de datos unificadas de hashtags tienen **`r hashtags %>% nrow()`** observaciones y **`r hashtags %>% ncol()`** variables.
    -   El objeto creado en R que unifica todas las bases de datos de hashtags ocupa **`r scales::unit_format(unit = "MB", scale = 1e-6, accuracy = 0.01)(as.numeric(lobstr::obj_size(hashtags)))`** de la memoria RAM en la computadora.

## Conclusiones

Tenemos 3 bases de datos:

-   **edges**: información sobre cada tweet.
-   **vertices**: información sobre cada tweetero.
-   **hashtags**: información sobre cada hashtag.

## Notas

```{r}
#| label: tbl-edges
#| tbl-cap: Total de edges por cada base de datos 

edges %>% 
  count(source) %>% 
  janitor::adorn_totals() %>% 
  gt() %>%
  tab_style(
    style = list(
      cell_text(weight = "bold")
    ),
    locations = cells_body(rows = source == "Total")
  ) %>% 
  tab_options(
    column_labels.font.weight = "bold",
    row.striping.include_table_body = TRUE
    )

```

```{r}
#| label: tbl-vertices
#| tbl-cap: Total de vértices por cada base de datos 

vertices %>% 
  count(source) %>% 
  janitor::adorn_totals() %>% 
  gt() %>%
  tab_style(
    style = list(
      cell_text(weight = "bold")
    ),
    locations = cells_body(rows = source == "Total")
  ) %>% 
  tab_options(
    column_labels.font.weight = "bold",
    row.striping.include_table_body = TRUE
    )


```

```{r}
#| label: tbl-hashtags
#| tbl-cap: Total de hashtags por cada base de datos 

hashtags %>% 
  count(source) %>% 
  janitor::adorn_totals() %>% 
  gt() %>%
  tab_style(
    style = list(
      cell_text(weight = "bold")
    ),
    locations = cells_body(rows = source == "Total")
  ) %>% 
  tab_options(
    column_labels.font.weight = "bold",
    row.striping.include_table_body = TRUE
    )


```

## Exportar data

```{r}
#| eval: false

edges %>% 
  export(here("data/edges.xlsx"),
         asTable=TRUE,
         overwrite=TRUE)

vertices %>% 
  export(here("data/vertices.xlsx"),
         asTable=TRUE,
         overwrite=TRUE)

hashtags %>% 
  export(here("data/hashtags.xlsx"),
         asTable=TRUE,
         overwrite=TRUE)

hashtags_dic %>% 
  export(here("data/diccionario_hashtags.xlsx"),
         asTable=TRUE,
         overwrite=TRUE)

```

-   El archivo `edges.xlsx` unificado pesa **`r fs::file_info("data/edges.xlsx") %>% summarise(size=sum(size))`B**.
-   El archivo `vertices.xlsx` unificado pesa **`r fs::file_info("data/vertices.xlsx") %>% summarise(size=sum(size))`B**.
-   El archivo `hashtags.xlsx` unificado pesa **`r fs::file_info("data/hashtags.xlsx") %>% summarise(size=sum(size))`B**.

```{r}
#| label: notas
#| eval: false
#| include: false


# vertex_3 ? vertex_22 ?
edges<-
  xlsx_files %>% 
  map_dfr(import, skip = 1,
          .id = "source") %>% 
  clean_names() %>% 
  drop_na(vertex_1)# averiguar por que hay dos columnas más de las que deberia

xlsx_files %>% 
  map(import, skip = 1) %>% 
  map(~ .x %>%
        clean_names() %>%
        names() %>% 
        length())# no tienen la misma cantidad de columnas.

```

Descargue el excel de [`edges.xlsx`](https://github.com/aito123/proyecto1/raw/master/data/edges.xlsx), [`vertices.xlsx`](https://github.com/aito123/proyecto1/raw/master/data/vertices.xlsx) o [`hashtags.xlsx`](https://github.com/aito123/proyecto1/raw/master/data/hashtags.xlsx)
